{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction To Sequential Data Modeling\n",
    "Author/Perpetrator: Carlo Graziani, including materials on LLMs by Varuni Sastri, and discussion/editorial work by Taylor Childers, Archit Vasan, Bethany Lusch, and Venkat Vishwanath (Argonne)\n",
    "\n",
    "Word embedding visualizations adapted from Kevin Gimpel (Toyota Technological Institute at Chicago) [Visualizing BERT](https://home.ttic.edu/~kgimpel/viz-bert/viz-bert.html).\n",
    "\n",
    "Some inspiration from the blog post [\"The Illustrated Transformer\"](https://jalammar.github.io/illustrated-transformer/) by Jay Alammar, highly recommended reading before next week's deeper dive into Transformer tech by Archit Vasan.  Another useful resource is [this ALCF tutorial](https://github.com/argonne-lcf/llm-workshop/blob/main/tutorials/01-llm-101/LLMs101.ipynb).\n",
    "\n",
    "Before you begin, make sure that you have your environment set up and your repo refreshed, as described in previous lessons, and reviewed in the accompanying 'Readme.md' file. Make sure that you select the kernel 'datascience/conda-2023-01-10' at the top-left of the Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Sequential Data\n",
    "\n",
    "The modern terminology for the analysis of sequential data is \"large language modeling\" (LLM). This usage comes from Natural Language Processing (NLP), and is perhaps unfortunate---especially from the perspective of \"AI For Science,\" because, as I hope to clarify shortly, this kind of modeling is more generally useful than just for NLP.\n",
    "\n",
    "This session is dedicated to setting out the basics of sequential data modeling, and introducing (and, where possible motivating) a few key elements required for DL approaches to such modeling---principally transformers.\n",
    "\n",
    "## A Basic LLM Pipeline: Text Prediction\n",
    "\n",
    "Let's download and run a model from the HuggingFace model hub, to start getting a feeling for one very popular LLM activity: text prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Administrivia: modify this notebook so output text wraps.\n",
    "from IPython.display import HTML, display\n",
    "def set_css():\n",
    "  display(HTML('''\n",
    "  <style>\n",
    "    pre {\n",
    "      white-space: pre-wrap;\n",
    "    }\n",
    "  </style>\n",
    "  '''))\n",
    "get_ipython().events.register('pre_run_cell', set_css)\n",
    "\n",
    "# Set various proxies to download models and data\n",
    "# !export HTTP_PROXY=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
    "# !export HTTPS_PROXY=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
    "# !export http_proxy=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
    "# !export https_proxy=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
    "# !export ftp_proxy=\"http://proxy-01.pub.alcf.anl.gov:3128\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "      white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (4.26.0)\n",
      "Requirement already satisfied: filelock in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from transformers) (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: requests in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows, we will ask an LLM based on the gpt2 model to complete the phrase \"I'm late because\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "      white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 22:20:36.377607: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages/h5py/__init__.py:36: UserWarning: h5py is running against HDF5 1.12.2 when it was built against 1.12.1, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n",
      "/soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages/transformers/generation/utils.py:1186: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How should I do good science?\n",
      "\n",
      "The above chart is a good guide to how to do science and to make your own science experiments. The questions on the right side of this chart are questions that you need an answer about with the right questions. The questions are not as complex as you realize and in some cases you've already answered them right when you're finished, so you might as well avoid doing them. If you have any specific challenges or questions please let me know and I will get\n",
      "******************\"\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# In this framework, setting  up a \"pipeline\" involves selecting a (pre-trained) model,\n",
    "# and a task---in this case, text generation \n",
    "generator = pipeline(\"text-generation\", model='gpt2')\n",
    "\n",
    "prompt = \"How should I do good science?\"\n",
    "\n",
    "# We request 5 completions of the prompt, of length 25 words\n",
    "res = generator(prompt, max_length=100, num_return_sequences=1)\n",
    "\n",
    "# What did we get?\n",
    "for each in res:\n",
    "    print(each['generated_text'])\n",
    "    print('******************\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huh. These seem pretty random.  What happens if we predict a single sentence, but extend its length?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "      white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pipeline in module transformers.pipelines:\n",
      "\n",
      "pipeline(task: str = None, model: Optional = None, config: Union[str, transformers.configuration_utils.PretrainedConfig, NoneType] = None, tokenizer: Union[str, transformers.tokenization_utils.PreTrainedTokenizer, transformers.tokenization_utils_fast.PreTrainedTokenizerFast, NoneType] = None, feature_extractor: Union[str, ForwardRef('SequenceFeatureExtractor'), NoneType] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, use_auth_token: Union[str, bool, NoneType] = None, device: Union[int, str, ForwardRef('torch.device'), NoneType] = None, device_map=None, torch_dtype=None, trust_remote_code: Optional[bool] = None, model_kwargs: Dict[str, Any] = None, pipeline_class: Optional[Any] = None, **kwargs) -> transformers.pipelines.base.Pipeline\n",
      "    Utility factory method to build a [`Pipeline`].\n",
      "    \n",
      "    Pipelines are made of:\n",
      "    \n",
      "        - A [tokenizer](tokenizer) in charge of mapping raw textual input to token.\n",
      "        - A [model](model) to make predictions from the inputs.\n",
      "        - Some (optional) post processing for enhancing model's output.\n",
      "    \n",
      "    Args:\n",
      "        task (`str`):\n",
      "            The task defining which pipeline will be returned. Currently accepted tasks are:\n",
      "    \n",
      "            - `\"audio-classification\"`: will return a [`AudioClassificationPipeline`].\n",
      "            - `\"automatic-speech-recognition\"`: will return a [`AutomaticSpeechRecognitionPipeline`].\n",
      "            - `\"conversational\"`: will return a [`ConversationalPipeline`].\n",
      "            - `\"depth-estimation\"`: will return a [`DepthEstimationPipeline`].\n",
      "            - `\"document-question-answering\"`: will return a [`DocumentQuestionAnsweringPipeline`].\n",
      "            - `\"feature-extraction\"`: will return a [`FeatureExtractionPipeline`].\n",
      "            - `\"fill-mask\"`: will return a [`FillMaskPipeline`]:.\n",
      "            - `\"image-classification\"`: will return a [`ImageClassificationPipeline`].\n",
      "            - `\"image-segmentation\"`: will return a [`ImageSegmentationPipeline`].\n",
      "            - `\"image-to-text\"`: will return a [`ImageToTextPipeline`].\n",
      "            - `\"object-detection\"`: will return a [`ObjectDetectionPipeline`].\n",
      "            - `\"question-answering\"`: will return a [`QuestionAnsweringPipeline`].\n",
      "            - `\"summarization\"`: will return a [`SummarizationPipeline`].\n",
      "            - `\"table-question-answering\"`: will return a [`TableQuestionAnsweringPipeline`].\n",
      "            - `\"text2text-generation\"`: will return a [`Text2TextGenerationPipeline`].\n",
      "            - `\"text-classification\"` (alias `\"sentiment-analysis\"` available): will return a\n",
      "              [`TextClassificationPipeline`].\n",
      "            - `\"text-generation\"`: will return a [`TextGenerationPipeline`]:.\n",
      "            - `\"token-classification\"` (alias `\"ner\"` available): will return a [`TokenClassificationPipeline`].\n",
      "            - `\"translation\"`: will return a [`TranslationPipeline`].\n",
      "            - `\"translation_xx_to_yy\"`: will return a [`TranslationPipeline`].\n",
      "            - `\"video-classification\"`: will return a [`VideoClassificationPipeline`].\n",
      "            - `\"visual-question-answering\"`: will return a [`VisualQuestionAnsweringPipeline`].\n",
      "            - `\"zero-shot-classification\"`: will return a [`ZeroShotClassificationPipeline`].\n",
      "            - `\"zero-shot-image-classification\"`: will return a [`ZeroShotImageClassificationPipeline`].\n",
      "            - `\"zero-shot-object-detection\"`: will return a [`ZeroShotObjectDetectionPipeline`].\n",
      "    \n",
      "        model (`str` or [`PreTrainedModel`] or [`TFPreTrainedModel`], *optional*):\n",
      "            The model that will be used by the pipeline to make predictions. This can be a model identifier or an\n",
      "            actual instance of a pretrained model inheriting from [`PreTrainedModel`] (for PyTorch) or\n",
      "            [`TFPreTrainedModel`] (for TensorFlow).\n",
      "    \n",
      "            If not provided, the default for the `task` will be loaded.\n",
      "        config (`str` or [`PretrainedConfig`], *optional*):\n",
      "            The configuration that will be used by the pipeline to instantiate the model. This can be a model\n",
      "            identifier or an actual pretrained model configuration inheriting from [`PretrainedConfig`].\n",
      "    \n",
      "            If not provided, the default configuration file for the requested model will be used. That means that if\n",
      "            `model` is given, its default configuration will be used. However, if `model` is not supplied, this\n",
      "            `task`'s default model's config is used instead.\n",
      "        tokenizer (`str` or [`PreTrainedTokenizer`], *optional*):\n",
      "            The tokenizer that will be used by the pipeline to encode data for the model. This can be a model\n",
      "            identifier or an actual pretrained tokenizer inheriting from [`PreTrainedTokenizer`].\n",
      "    \n",
      "            If not provided, the default tokenizer for the given `model` will be loaded (if it is a string). If `model`\n",
      "            is not specified or not a string, then the default tokenizer for `config` is loaded (if it is a string).\n",
      "            However, if `config` is also not given or not a string, then the default tokenizer for the given `task`\n",
      "            will be loaded.\n",
      "        feature_extractor (`str` or [`PreTrainedFeatureExtractor`], *optional*):\n",
      "            The feature extractor that will be used by the pipeline to encode data for the model. This can be a model\n",
      "            identifier or an actual pretrained feature extractor inheriting from [`PreTrainedFeatureExtractor`].\n",
      "    \n",
      "            Feature extractors are used for non-NLP models, such as Speech or Vision models as well as multi-modal\n",
      "            models. Multi-modal models will also require a tokenizer to be passed.\n",
      "    \n",
      "            If not provided, the default feature extractor for the given `model` will be loaded (if it is a string). If\n",
      "            `model` is not specified or not a string, then the default feature extractor for `config` is loaded (if it\n",
      "            is a string). However, if `config` is also not given or not a string, then the default feature extractor\n",
      "            for the given `task` will be loaded.\n",
      "        framework (`str`, *optional*):\n",
      "            The framework to use, either `\"pt\"` for PyTorch or `\"tf\"` for TensorFlow. The specified framework must be\n",
      "            installed.\n",
      "    \n",
      "            If no framework is specified, will default to the one currently installed. If no framework is specified and\n",
      "            both frameworks are installed, will default to the framework of the `model`, or to PyTorch if no model is\n",
      "            provided.\n",
      "        revision (`str`, *optional*, defaults to `\"main\"`):\n",
      "            When passing a task name or a string model identifier: The specific model version to use. It can be a\n",
      "            branch name, a tag name, or a commit id, since we use a git-based system for storing models and other\n",
      "            artifacts on huggingface.co, so `revision` can be any identifier allowed by git.\n",
      "        use_fast (`bool`, *optional*, defaults to `True`):\n",
      "            Whether or not to use a Fast tokenizer if possible (a [`PreTrainedTokenizerFast`]).\n",
      "        use_auth_token (`str` or *bool*, *optional*):\n",
      "            The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\n",
      "            when running `huggingface-cli login` (stored in `~/.huggingface`).\n",
      "        device (`int` or `str` or `torch.device`):\n",
      "            Defines the device (*e.g.*, `\"cpu\"`, `\"cuda:1\"`, `\"mps\"`, or a GPU ordinal rank like `1`) on which this\n",
      "            pipeline will be allocated.\n",
      "        device_map (`str` or `Dict[str, Union[int, str, torch.device]`, *optional*):\n",
      "            Sent directly as `model_kwargs` (just a simpler shortcut). When `accelerate` library is present, set\n",
      "            `device_map=\"auto\"` to compute the most optimized `device_map` automatically (see\n",
      "            [here](https://huggingface.co/docs/accelerate/main/en/package_reference/big_modeling#accelerate.cpu_offload)\n",
      "            for more information).\n",
      "    \n",
      "            <Tip warning={true}>\n",
      "    \n",
      "            Do not use `device_map` AND `device` at the same time as they will conflict\n",
      "    \n",
      "            </Tip>\n",
      "    \n",
      "        torch_dtype (`str` or `torch.dtype`, *optional*):\n",
      "            Sent directly as `model_kwargs` (just a simpler shortcut) to use the available precision for this model\n",
      "            (`torch.float16`, `torch.bfloat16`, ... or `\"auto\"`).\n",
      "        trust_remote_code (`bool`, *optional*, defaults to `False`):\n",
      "            Whether or not to allow for custom code defined on the Hub in their own modeling, configuration,\n",
      "            tokenization or even pipeline files. This option should only be set to `True` for repositories you trust\n",
      "            and in which you have read the code, as it will execute code present on the Hub on your local machine.\n",
      "        model_kwargs:\n",
      "            Additional dictionary of keyword arguments passed along to the model's `from_pretrained(...,\n",
      "            **model_kwargs)` function.\n",
      "        kwargs:\n",
      "            Additional keyword arguments passed along to the specific pipeline init (see the documentation for the\n",
      "            corresponding pipeline class for possible values).\n",
      "    \n",
      "    Returns:\n",
      "        [`Pipeline`]: A suitable pipeline for the task.\n",
      "    \n",
      "    Examples:\n",
      "    \n",
      "    ```python\n",
      "    >>> from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n",
      "    \n",
      "    >>> # Sentiment analysis pipeline\n",
      "    >>> analyzer = pipeline(\"sentiment-analysis\")\n",
      "    \n",
      "    >>> # Question answering pipeline, specifying the checkpoint identifier\n",
      "    >>> oracle = pipeline(\n",
      "    ...     \"question-answering\", model=\"distilbert-base-cased-distilled-squad\", tokenizer=\"bert-base-cased\"\n",
      "    ... )\n",
      "    \n",
      "    >>> # Named entity recognition pipeline, passing in a specific model and tokenizer\n",
      "    >>> model = AutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
      "    >>> tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
      "    >>> recognizer = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
      "    ```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "      white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How should I do good science?\n",
      "\n",
      "The scientific question of whether or not a particular science really has any scientific validity is frequently answered by examining different people's interests. But this kind of examination of one's research generally can only reveal one thing: whether or not that idea is valid. This can be interpreted as suggesting that science may or may not really be all that important and therefore only makes things more difficult for scientists — the latter having had the power to make those ideas go away when they so\n",
      "******************\"\n"
     ]
    }
   ],
   "source": [
    "res = generator(prompt, max_length=100, num_return_sequences=1)\n",
    "print(res[0]['generated_text'])\n",
    "print('******************\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some notable features here:\n",
    "\n",
    "1. Each sentence is different from the previous one. \n",
    "2. The sentences seem fairly disjointed, and go down weird rabbit holes after (or sometimes during) the first sentence.  \n",
    "3. The sentences always, or almost always, end in mid-sentence.  \n",
    "\n",
    "What explains this behavior?\n",
    "\n",
    "The answer to (1) is that this kind of text prediction (like ChatGPT's) is _generative_.  The text prompt is used to contruct a probability distribution over possible completions, and each generated sentence is a _sample_ from that distribution.\n",
    "\n",
    "The answer to (2) is: LLMs split up sentences into words or word fragments, called _tokens_. The way the samples are drawn is sequentially, one token at a time. Suppose the $k$-th token is denoted by the symbol $t_k$ ($t_k$ could be a word, a punctuation mark, a space, etc.). At stage $N$, the $N$-th token is drawn randomly from the distribution\n",
    "$$\n",
    "\\mathrm{Prob}(t_N | \\mathrm{prompt}, t_1, t_2,\\ldots,t_{N-1}),\n",
    "$$\n",
    "at stage $N+1$ the random draw is from\n",
    "$$\n",
    "\\mathrm{Prob}(t_{N+1} | \\mathrm{prompt}, t_1, t_2,\\ldots,t_{N-1},t_N),\n",
    "$$\n",
    "and so on.\n",
    "\n",
    "(If you are unfamiliar with this probability notation, know that an expression such as $\\mathrm{Prob}(X)$ should be read as \"the probability of occurrence of event $X$\", while the expression $\\mathrm{Prob}(X|Y)$ should be read as \"the probability of occurrence of the event $X$ _given_ that event $Y$ has been observed.\" This is called a _conditional probability_, and we often say \"Probability of $X$ conditioned on $Y$\" for $\\mathrm{Prob}(X|Y)$.  The observation of $Y$ changes the probability distribution governing the occurrence of $X$.  Here, the occurrence of the prompt, and of the first $N-1$ tokens, affects the probability distribution governing the $N$-th token $t_N$.)\n",
    "\n",
    "It follows from this fact that the sentences start growing apart at the first token $t_1$, and, depending on the model (in this case, gpt-2), are usually more strongly influenced by recent tokens than by older ones, so that $t_{90}$ is more strongly conditioned by it's immediate predecessors $t_{89}$, $t_{88}$, and $t_{87}$ than it is by the prompt, or by $t_1$, $t_2$, or $t_3$. We would say that this model's _attention_---it's ability to maintain context over sentences and paragraphs---is quite limited.\n",
    "\n",
    "The answer to (3) is also related to the generation mechanism.  With this style of generation, it is not possible to require that the text create exactly 100-token complete sentences. The best that one could do is to run the code so as to stop after the first (or second, or third) \"End of Sentence\" (EOS) token.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Where Do Deep Learning Model Architecture Choices Come From?\n",
    "\n",
    "  From the model development view, the elements of a DL architecture are usually the result of _a lot_ of trial-and-error by researchers.  However, at a deeper level, those choices are dictated by the nature of the data itself: some strategies that are successful for some types of data are nearly pointless for other types.\n",
    "\n",
    "  For example, last week Corey Adams lectured on the application of convolutional nets---network architectures based on local convolutional kernels---to image analysis. ConvNets were a remarkable discovery in the field, which arose through the desire to exploit _local 2-D spatial structure_ in images---edges, gradients, contrasts, large coherent features, small-scale details, and so on.  Convolutional kernels, together with pooling (and some other art) turn out to be exceptionally well-adapted to discovering such structure.\n",
    "\n",
    "  On the other hand, convolutions are not as useful if the data does not have that sort of spatial structure. It would be sort of senseless to reach for convnets to model, say, seasonal effects on product sales data across different manufacturing categories, or natural language sequences (although this has been tried).\n",
    "\n",
    "  So it makes sense to think about the nature of data when approaching this field. Generally speaking, there are two broad categories of data types that have dominated DL practice: vector data, and sequential data.  This course so far has trafficked in vector data, but with LLMs, we move into the domain of sequential data.\n",
    "\n",
    "  What distinguishes these two data types?\n",
    "\n",
    "### **Vector Data:** \n",
    "\n",
    "Fixed-length lists of real numbers, that can be visualized as living in a high-dimensional space, one dimension per list element.\n",
    "\n",
    "### Example: **Image Data**\n",
    "\n",
    "<p float=\"center\">\n",
    "<figure>\n",
    "\n",
    "  <img src=\"Figures/CIFAR-10.png\" width=\"500\" /> \n",
    "  \n",
    " </figure>\n",
    " \n",
    "</p>\n",
    "\n",
    "  **Typical queries and decisions:**\n",
    "  \n",
    "* Image classification\n",
    "* Inpainting---fill in blank regions\n",
    "* Segmentation---Identify elements in an image, e.g. cars, people, clouds...\n",
    "\n",
    "### Example: **Data from simulations**\n",
    "\n",
    "<p float=\"center\">\n",
    "<figure>\n",
    "\n",
    "  <img src=\"Figures/Simulations.png\" width=\"800\" /> \n",
    "  \n",
    "\n",
    " </figure>\n",
    " \n",
    "</p>\n",
    "\n",
    "  **Typical queries and decisions:**\n",
    "\n",
    "* Manifold finding/data reduction, i.e. how many dimensions are _really_ required to describe the data (this is basically what autoencoders do);\n",
    "* Emulation---train on simulation data, learn to produce similar output, or output at simulation settings not yet attempted, at much lower cost than the original simulators\n",
    "* Forecasting of weather, economics, pollution...\n",
    "\n",
    "### **Sequential Data:** \n",
    "\n",
    "_Sequences_ are variable-length lists, not necessarily real-valued, possibly containing gaps or requiring completion\n",
    "\n",
    "### Example: **Text Documents**\n",
    "\n",
    "<p float=\"center\">\n",
    "<figure>\n",
    "\n",
    "  <img src=\"Figures/Lorem.png\" width=\"500\" /> \n",
    "  \n",
    " </figure>\n",
    " \n",
    "</p>\n",
    "\n",
    "**Typical queries and decisions:**\n",
    "\n",
    "* Translation\n",
    "* Spell checking and correction\n",
    "* Text prediction and generation\n",
    "* Sentiment analysis\n",
    "\n",
    "### Example: **Genetic Sequences**\n",
    "\n",
    "<p float=\"center\">\n",
    "<figure>\n",
    "\n",
    "  <img src=\"Figures/RNA-codons.svg.png\" width=\"500\" /> \n",
    "  \n",
    " </figure>\n",
    " \n",
    "</p>\n",
    "\n",
    "**Typical queries and decisions:**\n",
    "\n",
    "* Prediction of likely variants/mutations from DNA variability\n",
    "* Realistic DNA sequence synthesis\n",
    "* Predicting gene expression\n",
    "\n",
    "### Example: **Protein Chains**\n",
    "\n",
    "<p float=\"center\">\n",
    "<figure>\n",
    "\n",
    "  <img src=\"Figures/Protein-Structure-06.png\" width=\"500\" /> \n",
    "  \n",
    " </figure>\n",
    " \n",
    "</p>\n",
    "\n",
    "**Typical queries and decisions:**\n",
    "\n",
    "* Predict folding structure\n",
    "* Predict chemical/binding properties\n",
    "\n",
    "\n",
    "\n",
    "Other examples of scientifically important  types of sequential data include chemical compounds (sequences of atoms) and weather states (sequences of spatially-resolved temperatures, pressures, humidities, etc.). \n",
    "\n",
    "It should be clear from the above that sequential data is much richer and more highly-structured, in general, than vector data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's take a break.  In the meantime, go back to the LLM pipeline that we built at the beginning, and try seeing what kind of text prediction result you can obtain through \"prompt engineering\": try making longer, or more constraining prompts, and see if you can get more sensible results from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elements of DL Sequence Modeling\n",
    "\n",
    "In 2017, the paper [Attention is All You Need](https://arxiv.org/abs/1706.03762) (Vaswani et al.) introduced the modern _transformer architecture_. Transformers were game-changers in the subject of sequential data modeling, but in important respects they built upon elements that were already in use in existing sequential data architectures, such as recurrent neural networks (RNNs), which they displaced.\n",
    "\n",
    "Let's look at two of those key elements that are needed by modern sequential models (AKA \"LLMs\"): tokenization, and word embedding. The third key element---attention---will be covered next week.\n",
    "\n",
    "### Tokenization\n",
    "\n",
    "Recall that unlike vector data, sequential data can have values that are essentially arbitrary---integers, real numbers, natural language words, DNA codons, and so on.  LLMs are trained and used in a manner that is largely agnostic of the data type.  This is possible because in a step preliminary to training, LLMs convert the data to _tokens_. Tokens are elements of a finite, discrete set---a _vocabulary_, with a certain fixed _vocabulary size_.  In the case of English natural language, the vocabulary may be made up of whole words, plus punctuation, spaces, etc. with a vocabulary size approaching 500,000; or it may be made up of sub-words, or word stems, or from other clever coding schemes, with reduced vocabulary size---as low as 30,000.\n",
    "\n",
    "There is clearly a tension represented by tokenization choice: On the one hand, there are great benefits to reducing the vocabulary size, because this can lead to substantial reductions in the number of parameters required by an LLM.  On the other hand, the actual distribution of sequence elements is more likely to be exposed to the model by more complex tokenizations, with larger vocabulary sizes.\n",
    "\n",
    "For example, take a phrase such as \"The chef added salt to the soup, because it required seasoning.\" The LLM needs to be able to parse such a sentence and discern, for example, that the article \"it\" refers to \"the soup\", and not to \"the chef\" or \"salt\" (how it does this is the subject of Attention, discussed next week).  It should be clear that such relationship are easier to tease out from a word tokenization (\"The\", \"chef\", \"added\"...) than from, say, a character-by-character tokenization (\"t\", \"h\", \"e\", \"c\"...). On the other hand, a character-by-character tokenization has a much smaller vocabulary size ($\\le 40$ including punctuation, spaces, etc.), whereas an English word-based vocabulary would have a vocabulary of about 500,000 (although the majority of these would be rarely-used words).\n",
    "\n",
    "Let's look at some tokenization examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "      white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# A utility function to tokenize a sequence and print out some information about it.\n",
    "\n",
    "def tokenization_summary(tokenizer, sequence):\n",
    "\n",
    "    # get the vocabulary\n",
    "    vocab = tokenizer.vocab\n",
    "    # Number of entries to print\n",
    "    n = 10\n",
    "\n",
    "    # Print subset of the vocabulary\n",
    "    print(\"Subset of tokenizer.vocab:\")\n",
    "    for i, (token, index) in enumerate(tokenizer.vocab.items()):\n",
    "        print(f\"{token}: {index}\")\n",
    "        if i >= n - 1:\n",
    "            break\n",
    "\n",
    "    print(\"Vocab size of the tokenizer = \", len(vocab))\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "    # .tokenize chunks the existing sequence into different tokens based on the rules and vocab of the tokenizer.\n",
    "    tokens = tokenizer.tokenize(sequence)\n",
    "    print(\"Tokens : \", tokens)\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "    # .convert_tokens_to_ids or .encode or .tokenize converts the tokens to their corresponding numerical representation.\n",
    "    #  .convert_tokens_to_ids has a 1-1 mapping between tokens and numerical representation\n",
    "    # ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    # print(\"encoded Ids: \", ids)\n",
    "\n",
    "    # .encode also adds additional information like Start of sequence tokens and End of sequene\n",
    "    print(\"tokenized sequence : \", tokenizer.encode(sequence))\n",
    "\n",
    "    # .tokenizer has additional information about attention_mask.\n",
    "    # encode = tokenizer(sequence)\n",
    "    # print(\"Encode sequence : \", encode)\n",
    "    # print(\"------------------------------------------\")\n",
    "\n",
    "    # .decode decodes the ids to raw text\n",
    "    ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    decode = tokenizer.decode(ids)\n",
    "    print(\"Decode sequence : \", decode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "      white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer_1  =  AutoTokenizer.from_pretrained(\"gpt2\") # GPT-2 uses \"Byte-Pair Encoding (BPE)\"\n",
    "\n",
    "sequence = \"Counselor, please adjust your Zoom filter to appear as a human, rather than as a cat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "      white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[77, 6696, 1816, 284, 262, 3650]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_1.encode(\"nathan went to the store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "      white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' inch- Bender mic Sen- Here'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_1.decode([11111, 12, 34535, 12314, 2311, 12, 3423])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "      white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['SPECIAL_TOKENS_ATTRIBUTES',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_tokens',\n",
       " '_additional_special_tokens',\n",
       " '_auto_class',\n",
       " '_batch_encode_plus',\n",
       " '_bos_token',\n",
       " '_build_conversation_input_ids',\n",
       " '_call_one',\n",
       " '_cls_token',\n",
       " '_convert_encoding',\n",
       " '_convert_id_to_token',\n",
       " '_convert_token_to_id_with_added_voc',\n",
       " '_create_repo',\n",
       " '_decode',\n",
       " '_decode_use_source_tokenizer',\n",
       " '_encode_plus',\n",
       " '_eos_token',\n",
       " '_eventual_warn_about_too_long_sequence',\n",
       " '_eventually_correct_t5_max_length',\n",
       " '_from_pretrained',\n",
       " '_get_files_timestamps',\n",
       " '_get_padding_truncation_strategies',\n",
       " '_in_target_context_manager',\n",
       " '_mask_token',\n",
       " '_pad',\n",
       " '_pad_token',\n",
       " '_pad_token_type_id',\n",
       " '_processor_class',\n",
       " '_save_pretrained',\n",
       " '_sep_token',\n",
       " '_set_processor_class',\n",
       " '_switch_to_input_mode',\n",
       " '_switch_to_target_mode',\n",
       " '_tokenizer',\n",
       " '_unk_token',\n",
       " '_upload_modified_files',\n",
       " 'add_bos_token',\n",
       " 'add_prefix_space',\n",
       " 'add_special_tokens',\n",
       " 'add_tokens',\n",
       " 'additional_special_tokens',\n",
       " 'additional_special_tokens_ids',\n",
       " 'all_special_ids',\n",
       " 'all_special_tokens',\n",
       " 'all_special_tokens_extended',\n",
       " 'as_target_tokenizer',\n",
       " 'backend_tokenizer',\n",
       " 'batch_decode',\n",
       " 'batch_encode_plus',\n",
       " 'bos_token',\n",
       " 'bos_token_id',\n",
       " 'build_inputs_with_special_tokens',\n",
       " 'can_save_slow_tokenizer',\n",
       " 'clean_up_tokenization',\n",
       " 'cls_token',\n",
       " 'cls_token_id',\n",
       " 'convert_ids_to_tokens',\n",
       " 'convert_tokens_to_ids',\n",
       " 'convert_tokens_to_string',\n",
       " 'create_token_type_ids_from_sequences',\n",
       " 'decode',\n",
       " 'decoder',\n",
       " 'deprecation_warnings',\n",
       " 'encode',\n",
       " 'encode_plus',\n",
       " 'eos_token',\n",
       " 'eos_token_id',\n",
       " 'from_pretrained',\n",
       " 'get_added_vocab',\n",
       " 'get_special_tokens_mask',\n",
       " 'get_vocab',\n",
       " 'init_inputs',\n",
       " 'init_kwargs',\n",
       " 'is_fast',\n",
       " 'mask_token',\n",
       " 'mask_token_id',\n",
       " 'max_len_sentences_pair',\n",
       " 'max_len_single_sentence',\n",
       " 'max_model_input_sizes',\n",
       " 'model_input_names',\n",
       " 'model_max_length',\n",
       " 'name_or_path',\n",
       " 'num_special_tokens_to_add',\n",
       " 'pad',\n",
       " 'pad_token',\n",
       " 'pad_token_id',\n",
       " 'pad_token_type_id',\n",
       " 'padding_side',\n",
       " 'prepare_for_model',\n",
       " 'prepare_seq2seq_batch',\n",
       " 'pretrained_init_configuration',\n",
       " 'pretrained_vocab_files_map',\n",
       " 'push_to_hub',\n",
       " 'register_for_auto_class',\n",
       " 'sanitize_special_tokens',\n",
       " 'save_pretrained',\n",
       " 'save_vocabulary',\n",
       " 'sep_token',\n",
       " 'sep_token_id',\n",
       " 'set_truncation_and_padding',\n",
       " 'slow_tokenizer_class',\n",
       " 'special_tokens_map',\n",
       " 'special_tokens_map_extended',\n",
       " 'tokenize',\n",
       " 'train_new_from_iterator',\n",
       " 'truncate_sequences',\n",
       " 'truncation_side',\n",
       " 'unk_token',\n",
       " 'unk_token_id',\n",
       " 'verbose',\n",
       " 'vocab',\n",
       " 'vocab_files_names',\n",
       " 'vocab_size']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tokenizer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "      white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset of tokenizer.vocab:\n",
      "Ġdeveloping: 5922\n",
      "ĠGad: 20925\n",
      "102: 15377\n",
      "ocom: 42829\n",
      "Ġarguments: 7159\n",
      "iley: 9618\n",
      "arag: 29967\n",
      "=~: 31820\n",
      "ĠChristina: 33673\n",
      "Ġdug: 18735\n",
      "Vocab size of the tokenizer =  50257\n",
      "------------------------------------------\n",
      "Tokens :  ['Coun', 'sel', 'or', ',', 'Ġplease', 'Ġadjust', 'Ġyour', 'ĠZoom', 'Ġfilter', 'Ġto', 'Ġappear', 'Ġas', 'Ġa', 'Ġhuman', ',', 'Ġrather', 'Ġthan', 'Ġas', 'Ġa', 'Ġcat']\n",
      "------------------------------------------\n",
      "encoded Ids:  [31053, 741, 273, 11, 3387, 4532, 534, 40305, 8106, 284, 1656, 355, 257, 1692, 11, 2138, 621, 355, 257, 3797]\n",
      "tokenized sequence :  [31053, 741, 273, 11, 3387, 4532, 534, 40305, 8106, 284, 1656, 355, 257, 1692, 11, 2138, 621, 355, 257, 3797]\n",
      "Decode sequence :  Counselor, please adjust your Zoom filter to appear as a human, rather than as a cat\n"
     ]
    }
   ],
   "source": [
    "tokenization_summary(tokenizer_1, sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-2 uses a so-called \"Byte-pair encoding\" (BPE), which can break up long words into  subwords (e.g. \"Coun\" \"sel \"lor\"). This allows for rare words (the majority of English vocabulary words) to be encoded in a smaller vocabulary (in this case, 50257 token IDs). This tokenization also incorporates initial whitespace before a word into the word for efficiency, so a word will be encoded differently whether it is at the beginning of the sentence (without space) or not. This is the reason for those odd-looking \"Ġ\" characters in the vocabulary.\n",
    "\n",
    "For a description of how BPE works, see [this article](https://huggingface.co/learn/nlp-course/en/chapter6/5).\n",
    "\n",
    "(Python tip: try typing \"help(tokenizer_1)\" for more information on what it's doing and how to use it).\n",
    "\n",
    "Let's look at a different tokenizer now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_2  =  AutoTokenizer.from_pretrained(\"bert-base-cased\") # BERT uses WordPiece encoding\n",
    "\n",
    "tokenization_summary(tokenizer_2, sequence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model (part of the BERT family) uses WordPiece encoding.  This is another clever strategy (described [here](https://huggingface.co/learn/nlp-course/en/chapter6/6)) that reduces the vocabulary size to 28996, by starting with a character-level encoding, then training on a text corpus to find ways to efficiently merge some of these preliminary tokens into others representing longer strings of frequent occurrence.  Note that \"Counsel\" occurs frequently enough to rate its own token, and the algorithm builds \"counselor\" out of \"counsel\"+\"or\" (actually, \"##or\", where the \"##\" is a tag indicating that the token is a word piece). Similarly for \"Zoom\"=\"Zoo\" + \"#m\".\n",
    "\n",
    "Note that one could obtain a simpler tokenizer by using elementary Python 'string' operations to split sentences on words, punctuation, and the like, obtaining _very_ large vocabulary sizes, but not requiring advance training on corpuses of text as WordPiece and BPE do. In NLP, however, such strategies are considered naive, because very large vocabulary sizes produce cripplingly large LLM parameter sizes.  It is better to train a tokenizer on actual data.\n",
    "\n",
    "Note also: there is, to this day, no approach to judging what is an _optimal_ tokenization---one that best preserves distributional information contained in the sequence without an exploding vocabulary size.\n",
    "\n",
    "### Token Embedding\n",
    "\n",
    "The strategy of choice for learning language structure from tokenized text is to find a clever way to map each token into a moderate-dimension vector space, adjusting the mapping so that \n",
    "\n",
    "1. Similar, or associated tokens take up residence nearby each other, and\n",
    "2. Different regions of the space correspond to different position in the sequence.\n",
    "\n",
    "Such a mapping from token ID to a point in a vector space is called a _token embedding_. The dimension of the vector space is often high (e.g. 1024-dimensional), but much smaller than the vocabulary size (30,000--500,000). The choice of this dimension is made based on a compromise between expressiveness and computational cost. Various approaches have been attempted for generating such embeddings, including static algorithms that operate on a corpus of tokenized data as preprocessors for NLP tasks.  Transformers, however, adjust their embeddings during training.\n",
    "\n",
    "The point of an embedding is to allow computational NLP architectures to operate on familiar, and easily tensorizable data entities---vectors---which can easily be subjected to the usual sorts of DL operations.\n",
    "\n",
    "Let's take a look at a visualization of the token embedding associated with a pre-trained BERT transformer model. The following is adapted from [Kevin Gimpel's visualization](https://home.ttic.edu/~kgimpel/viz-bert/viz-bert.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "      white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 01:35:32.843087: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages/h5py/__init__.py:36: UserWarning: h5py is running against HDF5 1.12.2 when it was built against 1.12.1, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n",
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary size is:  30522\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "plt.rcParams['figure.figsize'] = [100, 60]\n",
    "\n",
    "# Load BERT.\n",
    "model = BertModel.from_pretrained('bert-large-uncased-whole-word-masking')\n",
    "# Set the model to eval mode.\n",
    "model.eval()\n",
    "# This notebook assumes CPU execution. If you want to use GPUs, put the model on cuda and modify subsequent code blocks.\n",
    "#model.to('cuda')\n",
    "# Load tokenizer.\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking')\n",
    "\n",
    "# Save the BERT vocabulary to a file -- by default it will name this file \"vocab.txt\".\n",
    "tokenizer.save_vocabulary(save_directory='.')\n",
    "\n",
    "print(\"The vocabulary size is: \", model.config.vocab_size) # Size of the vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "      white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30522, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Get BERT's vocabulary embeddings.\n",
    "wordembs = model.get_input_embeddings()\n",
    "\n",
    "# Convert the vocabulary embeddings to numpy.\n",
    "allinds = np.arange(0,model.config.vocab_size,1)\n",
    "inputinds = torch.LongTensor(allinds)\n",
    "bertwordembs = wordembs(inputinds).detach().numpy()\n",
    "print(bertwordembs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "      white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.02419428, -0.00759981,  0.00445366],\n",
       "       [-0.02851291, -0.05074956, -0.01274622],\n",
       "       [-0.01905373, -0.05421471, -0.00300475]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertwordembs[0:3,0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the array bertwordembs contains 30522 vectors of size 1024, the latter being the dimension of the embedding space.\n",
    "\n",
    "The visualization of this data will be carried out by means of a projection to 2 dimensions by an algorithm called \"t-SNE\" (\"t-distributed stochastic neighbor embedding\"), which attempts to keep \"similar\" (in the high-dimensional space) points together, while spreading apart in the 2-dimensional projection points that are distant from each other in the high-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "      white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Read in the vocabulary\n",
    "filename = \"vocab.txt\"\n",
    "with open(filename,'r') as f:\n",
    "    bertwords = np.array([])\n",
    "    for line in f:\n",
    "        bertwords = np.append(bertwords, line.rstrip())\n",
    "\n",
    "# Determine vocabulary to use for t-SNE/visualization. The indices are hard-coded based partially on inspection:\n",
    "bert_char_indices_to_use = np.arange(999, 1063, 1)\n",
    "bert_voc_indices_to_plot = np.append(bert_char_indices_to_use, np.arange(1996, 5932, 1))\n",
    "bert_voc_indices_to_use = np.append(bert_char_indices_to_use, np.arange(1996, 11932, 1))\n",
    "\n",
    "bert_voc_indices_to_use_tensor = torch.LongTensor(bert_voc_indices_to_use)\n",
    "bert_word_embs_to_use = wordembs(bert_voc_indices_to_use_tensor).detach().numpy()\n",
    "bert_words_to_plot = bertwords[bert_voc_indices_to_plot]\n",
    "\n",
    "\n",
    "print(len(bert_voc_indices_to_plot))\n",
    "print(len(bert_voc_indices_to_use))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is to say, 10000 words will be used to compute the t-SNE data, but only 4000 of them will be plotted. We're ready to run the t-SNE projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "      white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 10000 samples in 0.003s...\n",
      "[t-SNE] Computed neighbors for 10000 samples in 1.369s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 10000\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 10000\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 10000\n",
      "[t-SNE] Computed conditional probabilities for sample 4000 / 10000\n",
      "[t-SNE] Computed conditional probabilities for sample 5000 / 10000\n",
      "[t-SNE] Computed conditional probabilities for sample 6000 / 10000\n",
      "[t-SNE] Computed conditional probabilities for sample 7000 / 10000\n",
      "[t-SNE] Computed conditional probabilities for sample 8000 / 10000\n",
      "[t-SNE] Computed conditional probabilities for sample 9000 / 10000\n",
      "[t-SNE] Computed conditional probabilities for sample 10000 / 10000\n",
      "[t-SNE] Mean sigma: 0.267747\n",
      "[t-SNE] Computed conditional probabilities in 0.191s\n",
      "[t-SNE] Iteration 50: error = 97.8543091, gradient norm = 0.0073397 (50 iterations in 0.603s)\n",
      "[t-SNE] Iteration 100: error = 96.0424423, gradient norm = 0.0002499 (50 iterations in 0.598s)\n",
      "[t-SNE] Iteration 150: error = 96.0277328, gradient norm = 0.0002313 (50 iterations in 0.575s)\n",
      "[t-SNE] Iteration 200: error = 96.0223083, gradient norm = 0.0004289 (50 iterations in 0.589s)\n",
      "[t-SNE] Iteration 250: error = 95.9962158, gradient norm = 0.0003859 (50 iterations in 0.607s)\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 95.996216\n",
      "[t-SNE] Iteration 300: error = 3.7067070, gradient norm = 0.0118384 (50 iterations in 0.547s)\n",
      "[t-SNE] Iteration 350: error = 3.2112553, gradient norm = 0.0108155 (50 iterations in 0.538s)\n",
      "[t-SNE] Iteration 400: error = 2.9605689, gradient norm = 0.0101543 (50 iterations in 0.546s)\n",
      "[t-SNE] Iteration 450: error = 2.7994153, gradient norm = 0.0097193 (50 iterations in 0.553s)\n",
      "[t-SNE] Iteration 500: error = 2.6870573, gradient norm = 0.0092254 (50 iterations in 0.558s)\n",
      "[t-SNE] Iteration 550: error = 2.6035261, gradient norm = 0.0087954 (50 iterations in 0.562s)\n",
      "[t-SNE] Iteration 600: error = 2.5405591, gradient norm = 0.0080966 (50 iterations in 0.563s)\n",
      "[t-SNE] Iteration 650: error = 2.4922242, gradient norm = 0.0074771 (50 iterations in 0.566s)\n",
      "[t-SNE] Iteration 700: error = 2.4540975, gradient norm = 0.0068921 (50 iterations in 0.567s)\n",
      "[t-SNE] Iteration 750: error = 2.4235065, gradient norm = 0.0064074 (50 iterations in 0.568s)\n",
      "[t-SNE] Iteration 800: error = 2.3981874, gradient norm = 0.0059385 (50 iterations in 0.567s)\n",
      "[t-SNE] Iteration 850: error = 2.3772619, gradient norm = 0.0054893 (50 iterations in 0.568s)\n",
      "[t-SNE] Iteration 900: error = 2.3599722, gradient norm = 0.0050429 (50 iterations in 0.569s)\n",
      "[t-SNE] Iteration 950: error = 2.3454602, gradient norm = 0.0046707 (50 iterations in 0.573s)\n",
      "[t-SNE] Iteration 1000: error = 2.3329506, gradient norm = 0.0043527 (50 iterations in 0.593s)\n",
      "[t-SNE] Iteration 1050: error = 2.3223422, gradient norm = 0.0040790 (50 iterations in 0.573s)\n",
      "[t-SNE] Iteration 1100: error = 2.3133943, gradient norm = 0.0037159 (50 iterations in 0.567s)\n",
      "[t-SNE] Iteration 1150: error = 2.3058209, gradient norm = 0.0033694 (50 iterations in 0.568s)\n",
      "[t-SNE] Iteration 1200: error = 2.2988780, gradient norm = 0.0032914 (50 iterations in 0.568s)\n",
      "[t-SNE] Iteration 1250: error = 2.2925093, gradient norm = 0.0030528 (50 iterations in 0.569s)\n",
      "[t-SNE] Iteration 1300: error = 2.2868729, gradient norm = 0.0029235 (50 iterations in 0.568s)\n",
      "[t-SNE] Iteration 1350: error = 2.2817400, gradient norm = 0.0027778 (50 iterations in 0.569s)\n",
      "[t-SNE] Iteration 1400: error = 2.2773068, gradient norm = 0.0024960 (50 iterations in 0.578s)\n",
      "[t-SNE] Iteration 1450: error = 2.2732463, gradient norm = 0.0024149 (50 iterations in 0.571s)\n",
      "[t-SNE] Iteration 1500: error = 2.2694182, gradient norm = 0.0023663 (50 iterations in 0.567s)\n",
      "[t-SNE] Iteration 1550: error = 2.2658043, gradient norm = 0.0022566 (50 iterations in 0.567s)\n",
      "[t-SNE] Iteration 1600: error = 2.2626219, gradient norm = 0.0020880 (50 iterations in 0.567s)\n",
      "[t-SNE] Iteration 1650: error = 2.2599740, gradient norm = 0.0016941 (50 iterations in 0.565s)\n",
      "[t-SNE] Iteration 1700: error = 2.2579458, gradient norm = 0.0014244 (50 iterations in 0.566s)\n",
      "[t-SNE] Iteration 1750: error = 2.2562373, gradient norm = 0.0013624 (50 iterations in 0.565s)\n",
      "[t-SNE] Iteration 1800: error = 2.2544727, gradient norm = 0.0014081 (50 iterations in 0.565s)\n",
      "[t-SNE] Iteration 1850: error = 2.2526369, gradient norm = 0.0013036 (50 iterations in 0.569s)\n",
      "[t-SNE] Iteration 1900: error = 2.2511683, gradient norm = 0.0011377 (50 iterations in 0.568s)\n",
      "[t-SNE] Iteration 1950: error = 2.2499149, gradient norm = 0.0010830 (50 iterations in 0.566s)\n",
      "[t-SNE] Iteration 2000: error = 2.2485285, gradient norm = 0.0011943 (50 iterations in 0.565s)\n",
      "[t-SNE] Iteration 2050: error = 2.2470179, gradient norm = 0.0012328 (50 iterations in 0.566s)\n",
      "[t-SNE] Iteration 2100: error = 2.2454760, gradient norm = 0.0013086 (50 iterations in 0.564s)\n",
      "[t-SNE] Iteration 2150: error = 2.2439137, gradient norm = 0.0013735 (50 iterations in 0.565s)\n",
      "[t-SNE] Iteration 2200: error = 2.2423830, gradient norm = 0.0012450 (50 iterations in 0.564s)\n",
      "[t-SNE] Iteration 2250: error = 2.2410057, gradient norm = 0.0012149 (50 iterations in 0.565s)\n",
      "[t-SNE] Iteration 2300: error = 2.2397578, gradient norm = 0.0011908 (50 iterations in 0.567s)\n",
      "[t-SNE] Iteration 2350: error = 2.2386532, gradient norm = 0.0010523 (50 iterations in 0.566s)\n",
      "[t-SNE] Iteration 2400: error = 2.2375569, gradient norm = 0.0010663 (50 iterations in 0.562s)\n",
      "[t-SNE] Iteration 2450: error = 2.2365170, gradient norm = 0.0009956 (50 iterations in 0.562s)\n",
      "[t-SNE] Iteration 2500: error = 2.2355249, gradient norm = 0.0010054 (50 iterations in 0.560s)\n",
      "[t-SNE] KL divergence after 2500 iterations: 2.235525\n"
     ]
    }
   ],
   "source": [
    "# Run t-SNE on the BERT vocabulary embeddings we selected:\n",
    "mytsne_words = TSNE(n_components=2,early_exaggeration=12,verbose=2,metric='cosine',init='pca',n_iter=2500)\n",
    "bert_word_embs_to_use_tsne = mytsne_words.fit_transform(bert_word_embs_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "      white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-37.83607 -43.85365\n",
      "-33.93866 -34.97797\n",
      "-27.601797 -26.877579\n",
      "-26.30496 -25.920177\n",
      "-36.81039 -41.027893\n",
      "-39.91933 -33.008156\n",
      "-28.432592 -47.043865\n",
      "-41.897068 -32.832333\n",
      "-37.221386 -30.209543\n",
      "-25.449034 -42.669342\n",
      "-35.85816 -32.519527\n",
      "-37.587475 -43.028637\n",
      "-25.41901 -42.70267\n",
      "-36.098637 -35.39466\n",
      "-30.813568 -27.778149\n",
      "-36.960392 -29.558401\n",
      "-35.77053 -29.326931\n",
      "-36.0878 -35.376377\n",
      "-34.592037 -38.480694\n",
      "-43.543327 -44.542786\n",
      "-30.463339 -30.815994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the transformed BERT vocabulary embeddings:\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "alltexts = list()\n",
    "for i, txt in enumerate(bert_words_to_plot):\n",
    "    x = bert_word_embs_to_use_tsne[i,0]\n",
    "    y = bert_word_embs_to_use_tsne[i,1]\n",
    "    \n",
    "    if -45 < x and x < -25 and -50 < y and y < -25:\n",
    "        print(x,y)\n",
    "        plt.scatter(bert_word_embs_to_use_tsne[i,0], bert_word_embs_to_use_tsne[i,1], s=0)\n",
    "        currtext = plt.text(bert_word_embs_to_use_tsne[i,0], bert_word_embs_to_use_tsne[i,1], txt, family='sans-serif')\n",
    "        alltexts.append(currtext)\n",
    "    \n",
    "# Save the plot before adjusting.\n",
    "plt.savefig('viz-bert-voc-tsne10k-viz4k-noadj.pdf', format='pdf')\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's are some close-ups of this projection. The first one has clusters of verbs with similar meanings.\n",
    "\n",
    "  <img src=\"Figures/viz-bert-voc-verbs.png\" align=\"center\" width=800/> \n",
    "\n",
    "Next, we see some sub-word clusters, containing the \"##\" tag used by BERT's WordPiece tokenization scheme. This cluster consists of English suffixes.\n",
    "\n",
    "  <img src=\"Figures/viz-bert-voc-suffixes.png\" align=\"center\" width=800/> \n",
    "\n",
    "Here is what appears to be a cluster of suffixes of jurisdiction names:\n",
    "\n",
    "  <img src=\"Figures/viz-bert-voc-entities.png\" align=\"center\" width=800/> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework\n",
    "\n",
    "1. **Tokenization** \n",
    "\n",
    "Write a generic Python tokenizer, which takes a set of text lines and tabulates the different words (that is, the tokens will be simply English words), keeping track of the frequency of each word.  Use the guidance in the accompanying notebook, 'Homework_1.ipynb'.\n",
    "\n",
    "2. **Embedding**\n",
    "\n",
    "Modify the embedding visualization code above to zoom in on various regions of the projections, and identify at least one interesting cluster of tokens."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience/conda-2023-01-10",
   "language": "python",
   "name": "conda-2023-01-10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
